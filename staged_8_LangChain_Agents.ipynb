{"cells":[{"cell_type":"markdown","id":"52824b89-532a-4e54-87e9-1410813cd39e","metadata":{"id":"52824b89-532a-4e54-87e9-1410813cd39e"},"source":["# LangChain: Agents"]},{"cell_type":"markdown","id":"m7PoVvm2mLRp","metadata":{"id":"m7PoVvm2mLRp"},"source":["Agents can receive a query by making use of a set of tools or resources at its disposal. These tools can include access to web search, Wikipedia, complex Mathematical libraries, LLMs, etc."]},{"cell_type":"markdown","id":"L-FWLLWFGhlk","metadata":{"id":"L-FWLLWFGhlk"},"source":["`Wikipedia-API` is easy to use Python wrapper for Wikipedias’ API. It supports extracting texts, sections, links, categories, translations, etc from Wikipedia. Documentation provides code snippets for the most common use cases."]},{"cell_type":"code","execution_count":8,"id":"974acf8e-8f88-42de-88f8-40a82cb58e8b","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12368,"status":"ok","timestamp":1696821120670,"user":{"displayName":"naveen b","userId":"07342808041236324682"},"user_tz":-330},"height":30,"id":"974acf8e-8f88-42de-88f8-40a82cb58e8b","outputId":"993f221f-41e0-4a94-8be9-d495cf277e10","tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: wikipedia in ./.venv/lib/python3.11/site-packages (1.4.0)\n","Requirement already satisfied: beautifulsoup4 in ./.venv/lib/python3.11/site-packages (from wikipedia) (4.12.3)\n","Requirement already satisfied: requests<3.0.0,>=2.0.0 in ./.venv/lib/python3.11/site-packages (from wikipedia) (2.31.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.11/site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.11/site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.11/site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2.2.1)\n","Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.11/site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2024.2.2)\n","Requirement already satisfied: soupsieve>1.2 in ./.venv/lib/python3.11/site-packages (from beautifulsoup4->wikipedia) (2.5)\n","\n","\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n","\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n","Note: you may need to restart the kernel to use updated packages.\n"]}],"source":["%pip install -U wikipedia"]},{"cell_type":"markdown","id":"0e3b9ad2","metadata":{"id":"0e3b9ad2"},"source":["## Built-in LangChain tools ✅"]},{"cell_type":"code","execution_count":9,"id":"7b93d0e8","metadata":{"height":130,"id":"7b93d0e8","tags":[]},"outputs":[],"source":["from langchain.agents import AgentType\n","from langchain.python import PythonREPL\n","from langchain.chat_models import ChatOpenAI\n","from langchain_experimental.tools.python.tool import PythonREPLTool\n","from langchain.agents import load_tools, initialize_agent\n","from langchain_experimental.agents.agent_toolkits.python.base import create_python_agent\n","# from langchain.agents.agent_toolkits import create_python_agent\n","\n","from utils import SaladChatOllama,MODEL"]},{"cell_type":"code","execution_count":null,"id":"f4195aeb","metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":10,"id":"7aadd5c1","metadata":{"height":30,"id":"7aadd5c1","tags":[]},"outputs":[],"source":["llm = SaladChatOllama(temperature=0,model=MODEL)"]},{"cell_type":"code","execution_count":57,"id":"394924ac","metadata":{"height":45,"id":"394924ac","tags":[]},"outputs":[],"source":["# Used to answer math questions and wikipedia articles related contents.\n","tools = load_tools([\"llm-math\",\"wikipedia\"], llm=llm)"]},{"cell_type":"code","execution_count":58,"id":"02cd4956","metadata":{"height":130,"id":"02cd4956","tags":[]},"outputs":[],"source":["agent_predict = initialize_agent(\n","    tools,\n","    llm,\n","    agent=AgentType.STRUCTURED_CHAT_ZERO_SHOT_REACT_DESCRIPTION,\n","    handle_parsing_errors=True,\n","    verbose = True)"]},{"cell_type":"code","execution_count":59,"id":"44601fe4-5f24-4ff2-a5df-a7e194a5b4f8","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":14257,"status":"ok","timestamp":1696821223531,"user":{"displayName":"naveen b","userId":"07342808041236324682"},"user_tz":-330},"height":30,"id":"44601fe4-5f24-4ff2-a5df-a7e194a5b4f8","outputId":"e02a9dd6-5947-400c-ef26-f08ff60a0318"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor] Entering Chain run with input:\n","\u001b[0m{\n","  \"input\": \"What is the  15% of 100?\"\n","}\n","\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 2:chain:LLMChain] Entering Chain run with input:\n","\u001b[0m{\n","  \"input\": \"What is the  15% of 100?\",\n","  \"agent_scratchpad\": \"\",\n","  \"stop\": [\n","    \"Observation:\"\n","  ]\n","}\n","\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 2:chain:LLMChain > 3:llm:SaladChatOllama] Entering LLM run with input:\n","\u001b[0m{\n","  \"prompts\": [\n","    \"System: Respond to the human as helpfully and accurately as possible. You have access to the following tools:\\n\\nCalculator: Useful for when you need to answer questions about math., args: {'tool_input': {'type': 'string'}}\\nwikipedia: A wrapper around Wikipedia. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects. Input should be a search query., args: {'query': {'title': 'Query', 'type': 'string'}}\\n\\nUse a json blob to specify a tool by providing an action key (tool name) and an action_input key (tool input).\\n\\nValid \\\"action\\\" values: \\\"Final Answer\\\" or Calculator, wikipedia\\n\\nProvide only ONE action per $JSON_BLOB, as shown:\\n\\n```\\n{\\n  \\\"action\\\": $TOOL_NAME,\\n  \\\"action_input\\\": $INPUT\\n}\\n```\\n\\nFollow this format:\\n\\nQuestion: input question to answer\\nThought: consider previous and subsequent steps\\nAction:\\n```\\n$JSON_BLOB\\n```\\nObservation: action result\\n... (repeat Thought/Action/Observation N times)\\nThought: I know what to respond\\nAction:\\n```\\n{\\n  \\\"action\\\": \\\"Final Answer\\\",\\n  \\\"action_input\\\": \\\"Final response to human\\\"\\n}\\n```\\n\\nBegin! Reminder to ALWAYS respond with a valid json blob of a single action. Use tools if necessary. Respond directly if appropriate. Format is Action:```$JSON_BLOB```then Observation:.\\nThought:\\nHuman: What is the  15% of 100?\"\n","  ]\n","}\n","\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 2:chain:LLMChain > 3:llm:SaladChatOllama] [1.98s] Exiting LLM run with output:\n","\u001b[0m{\n","  \"generations\": [\n","    [\n","      {\n","        \"text\": \"Action: Calculator\\naction_input: 100 * 0.15 = 15\\n\\n\",\n","        \"generation_info\": {\n","          \"model\": \"llama2\",\n","          \"created_at\": \"2024-05-05T15:43:34.323971095Z\",\n","          \"message\": {\n","            \"role\": \"assistant\",\n","            \"content\": \"\"\n","          },\n","          \"done\": true,\n","          \"total_duration\": 644412217,\n","          \"load_duration\": 1003502,\n","          \"prompt_eval_count\": 396,\n","          \"prompt_eval_duration\": 293589000,\n","          \"eval_count\": 29,\n","          \"eval_duration\": 253774000\n","        },\n","        \"type\": \"ChatGeneration\",\n","        \"message\": {\n","          \"lc\": 1,\n","          \"type\": \"constructor\",\n","          \"id\": [\n","            \"langchain\",\n","            \"schema\",\n","            \"messages\",\n","            \"AIMessage\"\n","          ],\n","          \"kwargs\": {\n","            \"content\": \"Action: Calculator\\naction_input: 100 * 0.15 = 15\\n\\n\",\n","            \"tool_calls\": [],\n","            \"invalid_tool_calls\": []\n","          }\n","        }\n","      }\n","    ]\n","  ],\n","  \"llm_output\": null,\n","  \"run\": null\n","}\n","\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 2:chain:LLMChain] [1.98s] Exiting Chain run with output:\n","\u001b[0m{\n","  \"text\": \"Action: Calculator\\naction_input: 100 * 0.15 = 15\\n\\n\"\n","}\n","\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor] [1.98s] Exiting Chain run with output:\n","\u001b[0m{\n","  \"output\": \"Action: Calculator\\naction_input: 100 * 0.15 = 15\\n\\n\"\n","}\n","{'input': 'What is the  15% of 100?', 'output': 'Action: Calculator\\naction_input: 100 * 0.15 = 15\\n\\n'}\n"]}],"source":["print(agent_predict(\"What is the  15% of 100?\"))"]},{"cell_type":"code","execution_count":60,"id":"441df699-0a52-4812-a0a7-4605204f0aa8","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":24188,"status":"ok","timestamp":1696821263573,"user":{"displayName":"naveen b","userId":"07342808041236324682"},"user_tz":-330},"height":96,"id":"441df699-0a52-4812-a0a7-4605204f0aa8","outputId":"3b693c0b-5bda-4683-ce53-a74717d0a229"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor] Entering Chain run with input:\n","\u001b[0m{\n","  \"input\": \"Dr.APJ Abdul Kalam has served as President of India. What was his tenure as President of India ?\"\n","}\n","\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 2:chain:LLMChain] Entering Chain run with input:\n","\u001b[0m{\n","  \"input\": \"Dr.APJ Abdul Kalam has served as President of India. What was his tenure as President of India ?\",\n","  \"agent_scratchpad\": \"\",\n","  \"stop\": [\n","    \"Observation:\"\n","  ]\n","}\n","\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 2:chain:LLMChain > 3:llm:SaladChatOllama] Entering LLM run with input:\n","\u001b[0m{\n","  \"prompts\": [\n","    \"System: Respond to the human as helpfully and accurately as possible. You have access to the following tools:\\n\\nCalculator: Useful for when you need to answer questions about math., args: {'tool_input': {'type': 'string'}}\\nwikipedia: A wrapper around Wikipedia. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects. Input should be a search query., args: {'query': {'title': 'Query', 'type': 'string'}}\\n\\nUse a json blob to specify a tool by providing an action key (tool name) and an action_input key (tool input).\\n\\nValid \\\"action\\\" values: \\\"Final Answer\\\" or Calculator, wikipedia\\n\\nProvide only ONE action per $JSON_BLOB, as shown:\\n\\n```\\n{\\n  \\\"action\\\": $TOOL_NAME,\\n  \\\"action_input\\\": $INPUT\\n}\\n```\\n\\nFollow this format:\\n\\nQuestion: input question to answer\\nThought: consider previous and subsequent steps\\nAction:\\n```\\n$JSON_BLOB\\n```\\nObservation: action result\\n... (repeat Thought/Action/Observation N times)\\nThought: I know what to respond\\nAction:\\n```\\n{\\n  \\\"action\\\": \\\"Final Answer\\\",\\n  \\\"action_input\\\": \\\"Final response to human\\\"\\n}\\n```\\n\\nBegin! Reminder to ALWAYS respond with a valid json blob of a single action. Use tools if necessary. Respond directly if appropriate. Format is Action:```$JSON_BLOB```then Observation:.\\nThought:\\nHuman: Dr.APJ Abdul Kalam has served as President of India. What was his tenure as President of India ?\"\n","  ]\n","}\n","\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 2:chain:LLMChain > 3:llm:SaladChatOllama] [1.89s] Exiting LLM run with output:\n","\u001b[0m{\n","  \"generations\": [\n","    [\n","      {\n","        \"text\": \" Action: Calculator\\nAction_input: 10th July 2002 - 25th May 2007\\n\\n\",\n","        \"generation_info\": {\n","          \"model\": \"llama2\",\n","          \"created_at\": \"2024-05-05T15:43:40.816749402Z\",\n","          \"message\": {\n","            \"role\": \"assistant\",\n","            \"content\": \"\"\n","          },\n","          \"done\": true,\n","          \"total_duration\": 515810088,\n","          \"load_duration\": 45174417,\n","          \"prompt_eval_count\": 408,\n","          \"prompt_eval_duration\": 96466000,\n","          \"eval_count\": 36,\n","          \"eval_duration\": 323452000\n","        },\n","        \"type\": \"ChatGeneration\",\n","        \"message\": {\n","          \"lc\": 1,\n","          \"type\": \"constructor\",\n","          \"id\": [\n","            \"langchain\",\n","            \"schema\",\n","            \"messages\",\n","            \"AIMessage\"\n","          ],\n","          \"kwargs\": {\n","            \"content\": \" Action: Calculator\\nAction_input: 10th July 2002 - 25th May 2007\\n\\n\",\n","            \"tool_calls\": [],\n","            \"invalid_tool_calls\": []\n","          }\n","        }\n","      }\n","    ]\n","  ],\n","  \"llm_output\": null,\n","  \"run\": null\n","}\n","\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 2:chain:LLMChain] [1.89s] Exiting Chain run with output:\n","\u001b[0m{\n","  \"text\": \" Action: Calculator\\nAction_input: 10th July 2002 - 25th May 2007\\n\\n\"\n","}\n","\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor] [1.89s] Exiting Chain run with output:\n","\u001b[0m{\n","  \"output\": \" Action: Calculator\\nAction_input: 10th July 2002 - 25th May 2007\\n\\n\"\n","}\n"]}],"source":["question = \"Dr.APJ Abdul Kalam has served as President of India. What was his tenure as President of India ?\"\n","result = agent_predict(question)"]},{"cell_type":"markdown","id":"2d2a4685","metadata":{"id":"2d2a4685"},"source":["## Create your Own Tool ✅"]},{"cell_type":"code","execution_count":76,"id":"73f8b595","metadata":{"height":47,"id":"73f8b595","tags":[]},"outputs":[],"source":["import random\n","from langchain.agents import tool"]},{"cell_type":"code","execution_count":79,"id":"61c64268","metadata":{"height":181,"id":"61c64268","tags":[]},"outputs":[],"source":["@tool\n","def get_inspiring_quote(text: str) -> str:\n","    \"\"\"Returns a random inspirational quote from the below quotes.\"\"\"\n","    quotes = [\n","        \"Believe you can and you're halfway there. -Theodore Roosevelt\",\n","        \"The only limit to our realization of tomorrow will be our doubts of today. -Franklin D. Roosevelt\",\n","        \"Success is not final, failure is not fatal: It is the courage to continue that counts. -Winston Churchill\",\n","        \"The only way to do great work is to love what you do. -Steve Jobs\",\n","        \"In the middle of every difficulty lies opportunity. -Albert Einstein\"\n","    ]\n","\n","    return random.choice(quotes)"]},{"cell_type":"code","execution_count":91,"id":"0d2fd9ee","metadata":{"height":130,"id":"0d2fd9ee","tags":[]},"outputs":[],"source":["agent= initialize_agent(\n","    tools + [get_inspiring_quote],\n","    llm,\n","    agent=AgentType.STRUCTURED_CHAT_ZERO_SHOT_REACT_DESCRIPTION,\n","    handle_parsing_errors=True,\n","    verbose = True)"]},{"cell_type":"markdown","id":"f9f30e7c-77f1-43fc-a966-140f05160378","metadata":{"id":"f9f30e7c-77f1-43fc-a966-140f05160378"},"source":["*To Note*:\n","\n","The agent may occasionally arrive at an inaccurate conclusion (agents are continuously evolving and improving!).\n","\n","If such a situation arises, please consider rerunning the query for a more accurate response."]},{"cell_type":"code","execution_count":92,"id":"1fcd13cb","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13429,"status":"ok","timestamp":1696823008189,"user":{"displayName":"naveen b","userId":"07342808041236324682"},"user_tz":-330},"height":96,"id":"1fcd13cb","outputId":"11b0e4b2-ec83-4034-c97c-bb086981eafb"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor] Entering Chain run with input:\n","\u001b[0m{\n","  \"input\": \"Give me a motivational quote for today\"\n","}\n","\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 2:chain:LLMChain] Entering Chain run with input:\n","\u001b[0m{\n","  \"input\": \"Give me a motivational quote for today\",\n","  \"agent_scratchpad\": \"\",\n","  \"stop\": [\n","    \"Observation:\"\n","  ]\n","}\n","\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 2:chain:LLMChain > 3:llm:SaladChatOllama] Entering LLM run with input:\n","\u001b[0m{\n","  \"prompts\": [\n","    \"System: Respond to the human as helpfully and accurately as possible. You have access to the following tools:\\n\\nCalculator: Useful for when you need to answer questions about math., args: {'tool_input': {'type': 'string'}}\\nwikipedia: A wrapper around Wikipedia. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects. Input should be a search query., args: {'query': {'title': 'Query', 'type': 'string'}}\\nget_inspiring_quote: get_inspiring_quote(text: str) -> str - Returns a random inspirational quote from the below quotes., args: {'text': {'title': 'Text', 'type': 'string'}}\\n\\nUse a json blob to specify a tool by providing an action key (tool name) and an action_input key (tool input).\\n\\nValid \\\"action\\\" values: \\\"Final Answer\\\" or Calculator, wikipedia, get_inspiring_quote\\n\\nProvide only ONE action per $JSON_BLOB, as shown:\\n\\n```\\n{\\n  \\\"action\\\": $TOOL_NAME,\\n  \\\"action_input\\\": $INPUT\\n}\\n```\\n\\nFollow this format:\\n\\nQuestion: input question to answer\\nThought: consider previous and subsequent steps\\nAction:\\n```\\n$JSON_BLOB\\n```\\nObservation: action result\\n... (repeat Thought/Action/Observation N times)\\nThought: I know what to respond\\nAction:\\n```\\n{\\n  \\\"action\\\": \\\"Final Answer\\\",\\n  \\\"action_input\\\": \\\"Final response to human\\\"\\n}\\n```\\n\\nBegin! Reminder to ALWAYS respond with a valid json blob of a single action. Use tools if necessary. Respond directly if appropriate. Format is Action:```$JSON_BLOB```then Observation:.\\nThought:\\nHuman: Give me a motivational quote for today\"\n","  ]\n","}\n","\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 2:chain:LLMChain > 3:llm:SaladChatOllama] [1.89s] Exiting LLM run with output:\n","\u001b[0m{\n","  \"generations\": [\n","    [\n","      {\n","        \"text\": \" {\\n  \\\"action\\\": \\\"get_inspiring_quote\\\",\\n  \\\"action_input\\\": \\\"A beautiful day begins with a beautiful mindset.\\\"\\n}\",\n","        \"generation_info\": {\n","          \"model\": \"llama2\",\n","          \"created_at\": \"2024-05-05T15:58:12.358547931Z\",\n","          \"message\": {\n","            \"role\": \"assistant\",\n","            \"content\": \"\"\n","          },\n","          \"done\": true,\n","          \"total_duration\": 749528829,\n","          \"load_duration\": 2145063,\n","          \"prompt_eval_count\": 446,\n","          \"prompt_eval_duration\": 268436000,\n","          \"eval_count\": 36,\n","          \"eval_duration\": 333625000\n","        },\n","        \"type\": \"ChatGeneration\",\n","        \"message\": {\n","          \"lc\": 1,\n","          \"type\": \"constructor\",\n","          \"id\": [\n","            \"langchain\",\n","            \"schema\",\n","            \"messages\",\n","            \"AIMessage\"\n","          ],\n","          \"kwargs\": {\n","            \"content\": \" {\\n  \\\"action\\\": \\\"get_inspiring_quote\\\",\\n  \\\"action_input\\\": \\\"A beautiful day begins with a beautiful mindset.\\\"\\n}\",\n","            \"tool_calls\": [],\n","            \"invalid_tool_calls\": []\n","          }\n","        }\n","      }\n","    ]\n","  ],\n","  \"llm_output\": null,\n","  \"run\": null\n","}\n","\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 2:chain:LLMChain] [1.89s] Exiting Chain run with output:\n","\u001b[0m{\n","  \"text\": \" {\\n  \\\"action\\\": \\\"get_inspiring_quote\\\",\\n  \\\"action_input\\\": \\\"A beautiful day begins with a beautiful mindset.\\\"\\n}\"\n","}\n","\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor] [1.89s] Exiting Chain run with output:\n","\u001b[0m{\n","  \"output\": \" {\\n  \\\"action\\\": \\\"get_inspiring_quote\\\",\\n  \\\"action_input\\\": \\\"A beautiful day begins with a beautiful mindset.\\\"\\n}\"\n","}\n"]}],"source":["try:\n","    result = agent(\"Give me a motivational quote for today\")\n","except:\n","    print(\"exception on external access\")"]},{"cell_type":"code","execution_count":93,"id":"f7293d65","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["{'input': 'Give me a motivational quote for today', 'output': ' {\\n  \"action\": \"get_inspiring_quote\",\\n  \"action_input\": \"A beautiful day begins with a beautiful mindset.\"\\n}'}\n"]}],"source":["print(result)"]}],"metadata":{"colab":{"provenance":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.7"}},"nbformat":4,"nbformat_minor":5}
