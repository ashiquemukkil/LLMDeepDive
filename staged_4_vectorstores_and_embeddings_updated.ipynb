{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "0d647f70",
      "metadata": {
        "id": "0d647f70"
      },
      "source": [
        "# Vectorstores and Embeddings\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "460a54b0",
      "metadata": {
        "id": "460a54b0"
      },
      "source": [
        "We just discussed `Document Loading` and `Splitting`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "ld6X_cCy1lyt",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ld6X_cCy1lyt",
        "outputId": "3177242a-a82b-4fea-c98e-ccefe17ee459"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pypdf in ./.venv/lib/python3.11/site-packages (4.1.0)\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "! pip3 install pypdf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "2437469e",
      "metadata": {
        "id": "2437469e",
        "tags": []
      },
      "outputs": [],
      "source": [
        "from langchain.document_loaders import PyPDFLoader\n",
        "\n",
        "# Load PDF\n",
        "loaders = [\n",
        "    # Duplicate documents on purpose - messy data\n",
        "    PyPDFLoader(\"data/machine_learning_linear_reg.pdf\"),\n",
        "    PyPDFLoader(\"data/machine_learning_Decision Tree.pdf\"),\n",
        "    PyPDFLoader(\"data/machine_learning_XGBoost.pdf\")\n",
        "]\n",
        "docs = []\n",
        "for loader in loaders:\n",
        "    docs.extend(loader.load())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "eb44bf0d",
      "metadata": {
        "id": "eb44bf0d",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Split\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size = 1500,\n",
        "    chunk_overlap = 150\n",
        ")\n",
        "splits = text_splitter.split_documents(docs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "b71e46cc",
      "metadata": {
        "id": "b71e46cc",
        "tags": []
      },
      "outputs": [],
      "source": [
        "splits = text_splitter.split_documents(docs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "e061f22d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e061f22d",
        "outputId": "5ec437c9-dbba-450c-ce5f-bd797e3fef61",
        "tags": []
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "9"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(splits)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "848e26fd",
      "metadata": {
        "id": "848e26fd"
      },
      "source": [
        "## Embeddings\n",
        "\n",
        "Let's take our splits and embed them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "d9dca7a8",
      "metadata": {
        "id": "d9dca7a8",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "from utils import SaladOllamaEmbeddings\n",
        "embedding = SaladOllamaEmbeddings()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "c4099521",
      "metadata": {
        "id": "c4099521",
        "tags": []
      },
      "outputs": [],
      "source": [
        "sentence1 = \"i like dogs\"\n",
        "sentence2 = \"i like canines\"\n",
        "sentence3 = \"the weather is ugly outside\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "2b327d3b",
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "d553549a",
      "metadata": {
        "id": "d553549a",
        "tags": []
      },
      "outputs": [],
      "source": [
        "embedding1 = embedding.embed_query(sentence1)\n",
        "embedding2 = embedding.embed_query(sentence2)\n",
        "embedding3 = embedding.embed_query(sentence3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "49fc0f8f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "49fc0f8f",
        "outputId": "c9ed7366-82f6-4244-da2a-f7e4c8c881b8",
        "tags": []
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "11769.093646134284"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "np.dot(embedding1, embedding2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "32a1fac7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "32a1fac7",
        "outputId": "6f664fc9-c2e1-4539-8647-377d07794af8",
        "tags": []
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.7710630976675918"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "np.dot(embedding1, embedding3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9dd18328",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9dd18328",
        "outputId": "3329acad-7ef8-4b5a-9e5b-6dbefc249fdf",
        "tags": []
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.7596682675219103"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "np.dot(embedding2, embedding3)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4fc7b24f",
      "metadata": {
        "id": "4fc7b24f"
      },
      "source": [
        "## Vectorstores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "da2213e6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "da2213e6",
        "outputId": "89bbb5ee-b38e-436c-8b35-68e6e3407748",
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: chromadb in ./.venv/lib/python3.11/site-packages (0.5.0)\n",
            "Requirement already satisfied: build>=1.0.3 in ./.venv/lib/python3.11/site-packages (from chromadb) (1.2.1)\n",
            "Requirement already satisfied: requests>=2.28 in ./.venv/lib/python3.11/site-packages (from chromadb) (2.31.0)\n",
            "Requirement already satisfied: pydantic>=1.9 in ./.venv/lib/python3.11/site-packages (from chromadb) (2.6.4)\n",
            "Requirement already satisfied: chroma-hnswlib==0.7.3 in ./.venv/lib/python3.11/site-packages (from chromadb) (0.7.3)\n",
            "Requirement already satisfied: fastapi>=0.95.2 in ./.venv/lib/python3.11/site-packages (from chromadb) (0.110.3)\n",
            "Requirement already satisfied: uvicorn>=0.18.3 in ./.venv/lib/python3.11/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.29.0)\n",
            "Requirement already satisfied: numpy>=1.22.5 in ./.venv/lib/python3.11/site-packages (from chromadb) (1.26.4)\n",
            "Requirement already satisfied: posthog>=2.4.0 in ./.venv/lib/python3.11/site-packages (from chromadb) (3.5.0)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in ./.venv/lib/python3.11/site-packages (from chromadb) (4.10.0)\n",
            "Requirement already satisfied: onnxruntime>=1.14.1 in ./.venv/lib/python3.11/site-packages (from chromadb) (1.17.3)\n",
            "Requirement already satisfied: opentelemetry-api>=1.2.0 in ./.venv/lib/python3.11/site-packages (from chromadb) (1.24.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in ./.venv/lib/python3.11/site-packages (from chromadb) (1.24.0)\n",
            "Requirement already satisfied: opentelemetry-instrumentation-fastapi>=0.41b0 in ./.venv/lib/python3.11/site-packages (from chromadb) (0.45b0)\n",
            "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in ./.venv/lib/python3.11/site-packages (from chromadb) (1.24.0)\n",
            "Requirement already satisfied: tokenizers>=0.13.2 in ./.venv/lib/python3.11/site-packages (from chromadb) (0.15.2)\n",
            "Requirement already satisfied: pypika>=0.48.9 in ./.venv/lib/python3.11/site-packages (from chromadb) (0.48.9)\n",
            "Requirement already satisfied: tqdm>=4.65.0 in ./.venv/lib/python3.11/site-packages (from chromadb) (4.66.2)\n",
            "Requirement already satisfied: overrides>=7.3.1 in ./.venv/lib/python3.11/site-packages (from chromadb) (7.7.0)\n",
            "Requirement already satisfied: importlib-resources in ./.venv/lib/python3.11/site-packages (from chromadb) (6.4.0)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in ./.venv/lib/python3.11/site-packages (from chromadb) (1.60.0)\n",
            "Requirement already satisfied: bcrypt>=4.0.1 in ./.venv/lib/python3.11/site-packages (from chromadb) (4.1.2)\n",
            "Requirement already satisfied: typer>=0.9.0 in ./.venv/lib/python3.11/site-packages (from chromadb) (0.12.3)\n",
            "Requirement already satisfied: kubernetes>=28.1.0 in ./.venv/lib/python3.11/site-packages (from chromadb) (29.0.0)\n",
            "Requirement already satisfied: tenacity>=8.2.3 in ./.venv/lib/python3.11/site-packages (from chromadb) (8.2.3)\n",
            "Requirement already satisfied: PyYAML>=6.0.0 in ./.venv/lib/python3.11/site-packages (from chromadb) (6.0.1)\n",
            "Requirement already satisfied: mmh3>=4.0.1 in ./.venv/lib/python3.11/site-packages (from chromadb) (4.1.0)\n",
            "Requirement already satisfied: orjson>=3.9.12 in ./.venv/lib/python3.11/site-packages (from chromadb) (3.9.15)\n",
            "Requirement already satisfied: packaging>=19.1 in ./.venv/lib/python3.11/site-packages (from build>=1.0.3->chromadb) (23.2)\n",
            "Requirement already satisfied: pyproject_hooks in ./.venv/lib/python3.11/site-packages (from build>=1.0.3->chromadb) (1.1.0)\n",
            "Requirement already satisfied: starlette<0.38.0,>=0.37.2 in ./.venv/lib/python3.11/site-packages (from fastapi>=0.95.2->chromadb) (0.37.2)\n",
            "Requirement already satisfied: certifi>=14.05.14 in ./.venv/lib/python3.11/site-packages (from kubernetes>=28.1.0->chromadb) (2024.2.2)\n",
            "Requirement already satisfied: six>=1.9.0 in ./.venv/lib/python3.11/site-packages (from kubernetes>=28.1.0->chromadb) (1.16.0)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in ./.venv/lib/python3.11/site-packages (from kubernetes>=28.1.0->chromadb) (2.9.0.post0)\n",
            "Requirement already satisfied: google-auth>=1.0.1 in ./.venv/lib/python3.11/site-packages (from kubernetes>=28.1.0->chromadb) (2.29.0)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in ./.venv/lib/python3.11/site-packages (from kubernetes>=28.1.0->chromadb) (1.8.0)\n",
            "Requirement already satisfied: requests-oauthlib in ./.venv/lib/python3.11/site-packages (from kubernetes>=28.1.0->chromadb) (2.0.0)\n",
            "Requirement already satisfied: oauthlib>=3.2.2 in ./.venv/lib/python3.11/site-packages (from kubernetes>=28.1.0->chromadb) (3.2.2)\n",
            "Requirement already satisfied: urllib3>=1.24.2 in ./.venv/lib/python3.11/site-packages (from kubernetes>=28.1.0->chromadb) (2.2.1)\n",
            "Requirement already satisfied: coloredlogs in ./.venv/lib/python3.11/site-packages (from onnxruntime>=1.14.1->chromadb) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in ./.venv/lib/python3.11/site-packages (from onnxruntime>=1.14.1->chromadb) (24.3.25)\n",
            "Requirement already satisfied: protobuf in ./.venv/lib/python3.11/site-packages (from onnxruntime>=1.14.1->chromadb) (4.25.3)\n",
            "Requirement already satisfied: sympy in ./.venv/lib/python3.11/site-packages (from onnxruntime>=1.14.1->chromadb) (1.12)\n",
            "Requirement already satisfied: deprecated>=1.2.6 in ./.venv/lib/python3.11/site-packages (from opentelemetry-api>=1.2.0->chromadb) (1.2.14)\n",
            "Requirement already satisfied: importlib-metadata<=7.0,>=6.0 in ./.venv/lib/python3.11/site-packages (from opentelemetry-api>=1.2.0->chromadb) (7.0.0)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.52 in ./.venv/lib/python3.11/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.63.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.24.0 in ./.venv/lib/python3.11/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.24.0)\n",
            "Requirement already satisfied: opentelemetry-proto==1.24.0 in ./.venv/lib/python3.11/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.24.0)\n",
            "Requirement already satisfied: opentelemetry-instrumentation-asgi==0.45b0 in ./.venv/lib/python3.11/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.45b0)\n",
            "Requirement already satisfied: opentelemetry-instrumentation==0.45b0 in ./.venv/lib/python3.11/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.45b0)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.45b0 in ./.venv/lib/python3.11/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.45b0)\n",
            "Requirement already satisfied: opentelemetry-util-http==0.45b0 in ./.venv/lib/python3.11/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.45b0)\n",
            "Requirement already satisfied: setuptools>=16.0 in ./.venv/lib/python3.11/site-packages (from opentelemetry-instrumentation==0.45b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (69.0.2)\n",
            "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in ./.venv/lib/python3.11/site-packages (from opentelemetry-instrumentation==0.45b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (1.16.0)\n",
            "Requirement already satisfied: asgiref~=3.0 in ./.venv/lib/python3.11/site-packages (from opentelemetry-instrumentation-asgi==0.45b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (3.8.1)\n",
            "Requirement already satisfied: monotonic>=1.5 in ./.venv/lib/python3.11/site-packages (from posthog>=2.4.0->chromadb) (1.6)\n",
            "Requirement already satisfied: backoff>=1.10.0 in ./.venv/lib/python3.11/site-packages (from posthog>=2.4.0->chromadb) (2.2.1)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in ./.venv/lib/python3.11/site-packages (from pydantic>=1.9->chromadb) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in ./.venv/lib/python3.11/site-packages (from pydantic>=1.9->chromadb) (2.16.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.11/site-packages (from requests>=2.28->chromadb) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.11/site-packages (from requests>=2.28->chromadb) (3.6)\n",
            "Requirement already satisfied: huggingface_hub<1.0,>=0.16.4 in ./.venv/lib/python3.11/site-packages (from tokenizers>=0.13.2->chromadb) (0.22.2)\n",
            "Requirement already satisfied: click>=8.0.0 in ./.venv/lib/python3.11/site-packages (from typer>=0.9.0->chromadb) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in ./.venv/lib/python3.11/site-packages (from typer>=0.9.0->chromadb) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in ./.venv/lib/python3.11/site-packages (from typer>=0.9.0->chromadb) (13.7.1)\n",
            "Requirement already satisfied: h11>=0.8 in ./.venv/lib/python3.11/site-packages (from uvicorn>=0.18.3->uvicorn[standard]>=0.18.3->chromadb) (0.14.0)\n",
            "Requirement already satisfied: httptools>=0.5.0 in ./.venv/lib/python3.11/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.6.1)\n",
            "Requirement already satisfied: python-dotenv>=0.13 in ./.venv/lib/python3.11/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.0.1)\n",
            "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in ./.venv/lib/python3.11/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.19.0)\n",
            "Requirement already satisfied: watchfiles>=0.13 in ./.venv/lib/python3.11/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.21.0)\n",
            "Requirement already satisfied: websockets>=10.4 in ./.venv/lib/python3.11/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (12.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in ./.venv/lib/python3.11/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in ./.venv/lib/python3.11/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in ./.venv/lib/python3.11/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9)\n",
            "Requirement already satisfied: filelock in ./.venv/lib/python3.11/site-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (3.13.3)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in ./.venv/lib/python3.11/site-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (2024.2.0)\n",
            "Requirement already satisfied: zipp>=0.5 in ./.venv/lib/python3.11/site-packages (from importlib-metadata<=7.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.18.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in ./.venv/lib/python3.11/site-packages (from rich>=10.11.0->typer>=0.9.0->chromadb) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in ./.venv/lib/python3.11/site-packages (from rich>=10.11.0->typer>=0.9.0->chromadb) (2.17.2)\n",
            "Requirement already satisfied: anyio<5,>=3.4.0 in ./.venv/lib/python3.11/site-packages (from starlette<0.38.0,>=0.37.2->fastapi>=0.95.2->chromadb) (4.3.0)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in ./.venv/lib/python3.11/site-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb) (10.0)\n",
            "Requirement already satisfied: mpmath>=0.19 in ./.venv/lib/python3.11/site-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in ./.venv/lib/python3.11/site-packages (from anyio<5,>=3.4.0->starlette<0.38.0,>=0.37.2->fastapi>=0.95.2->chromadb) (1.3.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in ./.venv/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer>=0.9.0->chromadb) (0.1.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in ./.venv/lib/python3.11/site-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.6.0)\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "! pip install chromadb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "201e6afa",
      "metadata": {
        "id": "201e6afa",
        "tags": []
      },
      "outputs": [],
      "source": [
        "from langchain.vectorstores import Chroma"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "id": "93960ac5",
      "metadata": {
        "id": "93960ac5",
        "tags": []
      },
      "outputs": [],
      "source": [
        "persist_directory = '/tmp/docs/chroma/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "id": "a195e72a",
      "metadata": {
        "id": "a195e72a",
        "tags": []
      },
      "outputs": [],
      "source": [
        "!rm -rf docs/chroma  # remove old database files if any"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "id": "798957e4",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/Users/ashique/Playground/LLMDeepDive\n"
          ]
        }
      ],
      "source": [
        "!pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "690efd0a",
      "metadata": {
        "id": "690efd0a",
        "tags": []
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'Chroma' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m vectordb \u001b[38;5;241m=\u001b[39m \u001b[43mChroma\u001b[49m\u001b[38;5;241m.\u001b[39mfrom_documents(\n\u001b[1;32m      2\u001b[0m     documents\u001b[38;5;241m=\u001b[39msplits,\n\u001b[1;32m      3\u001b[0m     embedding\u001b[38;5;241m=\u001b[39membedding,\n\u001b[1;32m      4\u001b[0m     persist_directory\u001b[38;5;241m=\u001b[39mpersist_directory\n\u001b[1;32m      5\u001b[0m )\n",
            "\u001b[0;31mNameError\u001b[0m: name 'Chroma' is not defined"
          ]
        }
      ],
      "source": [
        "vectordb = Chroma.from_documents(\n",
        "    documents=splits,\n",
        "    embedding=embedding,\n",
        "    persist_directory=persist_directory\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "id": "f777480c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f777480c",
        "outputId": "617e9039-dfdb-49ec-f213-2b1eadfae051",
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "9\n"
          ]
        }
      ],
      "source": [
        "print(vectordb._collection.count())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "efca7589",
      "metadata": {
        "id": "efca7589"
      },
      "source": [
        "### Similarity Search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3e20837d",
      "metadata": {
        "id": "3e20837d",
        "tags": []
      },
      "outputs": [],
      "source": [
        "question = \"Which algorith uses boosting technique ?\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f9bde572",
      "metadata": {
        "id": "f9bde572",
        "tags": []
      },
      "outputs": [],
      "source": [
        "docs = vectordb.similarity_search(question,k=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "41388af1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "41388af1",
        "outputId": "44b7df31-2ebf-41ec-de9c-a72958daba38",
        "tags": []
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(docs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "183434f6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "183434f6",
        "outputId": "d10b2667-8495-431b-e65c-c029035e9e23",
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "XGBoost   Introduc)on  XGBoost (Extreme Gradient Boos2ng) is a powerful and eﬃcient implementa2on of the gradient boos2ng algorithm. It is widely used for supervised learning tasks, including classiﬁca2on, regression, and ranking problems. XGBoost builds an ensemble of weak predic2on models, typically decision trees, to create a strong predic2ve model with high accuracy and generalizability.  How It Works  XGBoost sequen2ally builds a strong model by adding weak models that collec2vely minimize a predeﬁned loss func2on. It uses gradient boos2ng to op2mize the model by ﬁGng new models to the residuals of the previous models. XGBoost employs a combina2on of regulariza2on techniques and parallel processing to enhance model performance and reduce overﬁGng.  Mathema)cal Intui)on  XGBoost op2mizes the objec2ve func2on by compu2ng the ﬁrst and second deriva2ves of the loss func2on. It uses the Taylor series expansion to approximate the loss func2on, leading to a simpliﬁed yet eﬀec2ve op2miza2on process. XGBoost u2lizes techniques like gradient descent and tree pruning to eﬃciently handle complex datasets and achieve beKer generaliza2on. Limita)ons  Although XGBoost is known for its robustness and high performance, it can be computa2onally expensive and memory-intensive, par2cularly for large datasets. It may require ﬁne-tuning of various hyperparameters to achieve the best results, making it more complex to implement compared to simpler algorithms.\n"
          ]
        }
      ],
      "source": [
        "print(docs[0].page_content)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1edb21d8",
      "metadata": {
        "id": "1edb21d8"
      },
      "source": [
        "Let's save this so we can use it later!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ea657123",
      "metadata": {
        "id": "ea657123",
        "tags": []
      },
      "outputs": [],
      "source": [
        "vectordb.persist()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cefe9f6a",
      "metadata": {
        "id": "cefe9f6a"
      },
      "source": [
        "## Failure modes\n",
        "\n",
        "This seems great, and basic similarity search will get you 80% of the way there very easily.\n",
        "\n",
        "But there are some failure modes that can creep up.\n",
        "\n",
        "Here are some edge cases that can arise - we'll fix them in the next class."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "df0f29f9",
      "metadata": {
        "id": "df0f29f9",
        "tags": []
      },
      "outputs": [],
      "source": [
        "question = \"Does Linear Regression handle Outliers ?\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "02be97df",
      "metadata": {
        "id": "02be97df",
        "tags": []
      },
      "outputs": [],
      "source": [
        "docs = vectordb.similarity_search(question,k=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2a9f579e",
      "metadata": {
        "id": "2a9f579e"
      },
      "source": [
        "Notice that we're getting duplicate chunks (because of the duplicate `machine_learning_linear_reg.pdf` in the index).\n",
        "\n",
        "Semantic search fetches all similar documents, but does not enforce diversity.\n",
        "\n",
        "`docs[0]` and `docs[1]` are indentical."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d39f6954",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d39f6954",
        "outputId": "a9368338-6470-42d2-b24b-c895e58de5c0",
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "page_content='including its reliance on the linearity assump5on between the dependent and independent variables. If the rela5onship between the variables is non-linear, the model may not accurately represent the data. Addi5onally, linear regression is sensi5ve to outliers, and its performance may be impacted by the presence of mul5collinearity among the independent variables.' metadata={'page': 0, 'source': '/content/machine_learning_linear_reg.pdf'}\n"
          ]
        }
      ],
      "source": [
        "print(docs[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e04e3d1b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e04e3d1b",
        "outputId": "9f45d361-e3b9-4987-85c9-1b28283e040d",
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "page_content='including its reliance on the linearity assump5on between the dependent and independent variables. If the rela5onship between the variables is non-linear, the model may not accurately represent the data. Addi5onally, linear regression is sensi5ve to outliers, and its performance may be impacted by the presence of mul5collinearity among the independent variables.' metadata={'page': 0, 'source': '/content/machine_learning_linear_reg.pdf'}\n"
          ]
        }
      ],
      "source": [
        "print(docs[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3a3a915d",
      "metadata": {
        "id": "3a3a915d"
      },
      "source": [
        "We can see a new failure mode.\n",
        "\n",
        "The question below asks a question about the third lecture, but includes results from other lectures as well."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b19135e5",
      "metadata": {
        "id": "b19135e5",
        "tags": []
      },
      "outputs": [],
      "source": [
        "question = \"Why to use Decision Tree and When to use ?\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d434942c",
      "metadata": {
        "id": "d434942c",
        "tags": []
      },
      "outputs": [],
      "source": [
        "docs = vectordb.similarity_search(question,k=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c2c5df59",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c2c5df59",
        "outputId": "605c9ddf-445c-49cf-a668-1f0eb6ea02f4",
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'page': 1, 'source': '/content/machine_learning_Decision Tree.pdf'}\n",
            "{'page': 0, 'source': '/content/machine_learning_Decision Tree.pdf'}\n",
            "{'page': 0, 'source': '/content/machine_learning_Decision Tree.pdf'}\n",
            "{'page': 0, 'source': '/content/machine_learning_XGBoost.pdf'}\n",
            "{'page': 1, 'source': '/content/machine_learning_XGBoost.pdf'}\n"
          ]
        }
      ],
      "source": [
        "for doc in docs:\n",
        "    print(doc.metadata)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8e6cb50c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8e6cb50c",
        "outputId": "de219595-ace0-41ae-be3f-603bfb6765aa",
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "customiza2on and hyperparameter tuning, allowing users to op2mize model performance based on speciﬁc requirements. Disadvantages  Despite its advantages, XGBoost has certain limita2ons, such as the increased computa2onal complexity and longer training 2mes compared to simpler algorithms. It may require signiﬁcant computa2onal resources, limi2ng its applicability in resource-constrained environments. The black-box nature of the model can also hinder interpretability, making it challenging to understand the decision-making process for complex predic2ons.\n"
          ]
        }
      ],
      "source": [
        "print(docs[4].page_content)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5a29e8c9",
      "metadata": {
        "id": "5a29e8c9"
      },
      "source": [
        "## Addressing Diversity: Maximum marginal relevance\n",
        "\n",
        "Last class we introduced one problem: how to enforce diversity in the search results.\n",
        "\n",
        "`Maximum marginal relevance` strives to achieve both relevance to the query *and diversity* among the results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "I812-0LFJbqH",
      "metadata": {
        "id": "I812-0LFJbqH"
      },
      "outputs": [],
      "source": [
        "question = \"Disdvantages of Decision tree algorith\"\n",
        "docs_ss = vectordb.similarity_search(question,k=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f07f8793",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "f07f8793",
        "outputId": "f4bd5b3f-e205-4cc0-aa59-740b6f17ff68",
        "tags": []
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'their versa-lity, decision trees can be prone to overﬁEng, especially when dealing with complex data'"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "docs_ss[0].page_content[:100]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e9f7e165",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "e9f7e165",
        "outputId": "ac973c98-0856-4bb8-cc7c-970356fea254",
        "tags": []
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Decision trees oﬀer various advantages, including their interpretability and ease of understanding. '"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "docs_ss[1].page_content[:100]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4c4ca1b6",
      "metadata": {
        "id": "4c4ca1b6"
      },
      "source": [
        "Note the difference in results with `MMR`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "222234c5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "222234c5",
        "outputId": "386c3bbe-ce3b-44e5-d2bb-3e5c87d05b93",
        "tags": []
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Number of requested results 20 is greater than number of elements in index 12, updating n_results = 12\n"
          ]
        }
      ],
      "source": [
        "docs_mmr = vectordb.max_marginal_relevance_search(question,k=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "93b20226",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "93b20226",
        "outputId": "430bab8b-306c-4b61-f006-1a64e45ede82",
        "tags": []
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'their versa-lity, decision trees can be prone to overﬁEng, especially when dealing with complex data'"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "docs_mmr[0].page_content[:100]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "17d39762",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "17d39762",
        "outputId": "edd397a6-78aa-4b99-d2df-34d5024290f6",
        "tags": []
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Decision trees oﬀer various advantages, including their interpretability and ease of understanding. '"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "docs_mmr[1].page_content[:100]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b2b909bc",
      "metadata": {
        "id": "b2b909bc"
      },
      "source": [
        "## Addressing Specificity: working with metadata\n",
        "\n",
        "In last lecture, we showed that a question about the third lecture can include results from other lectures as well.\n",
        "\n",
        "To address this, many vectorstores support operations on `metadata`.\n",
        "\n",
        "`metadata` provides context for each embedded chunk."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Z_zpwU7ULVt5",
      "metadata": {
        "id": "Z_zpwU7ULVt5"
      },
      "outputs": [],
      "source": [
        "question = \"what did they say about XGBoost ?\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "X5oi1A0KLXvw",
      "metadata": {
        "id": "X5oi1A0KLXvw"
      },
      "outputs": [],
      "source": [
        "docs = vectordb.similarity_search(\n",
        "    question,\n",
        "    k=3,\n",
        "    filter={\"source\":\"/content/machine_learning_XGBoost.pdf\"}\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "BFCW5CbELZS3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BFCW5CbELZS3",
        "outputId": "c3675acd-b88c-438f-ad2f-d8a008f8b8e4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'page': 0, 'source': '/content/machine_learning_XGBoost.pdf'}\n",
            "{'page': 1, 'source': '/content/machine_learning_XGBoost.pdf'}\n",
            "{'page': 0, 'source': '/content/machine_learning_XGBoost.pdf'}\n"
          ]
        }
      ],
      "source": [
        "for d in docs:\n",
        "    print(d.metadata)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "__GRFkSBU8U6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "id": "__GRFkSBU8U6",
        "outputId": "ac404193-5e30-4268-a696-40bdea5f09ce"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'XGBoost   Introduc)on  XGBoost (Extreme Gradient Boos2ng) is a powerful and eﬃcient implementa2on of the gradient boos2ng algorithm. It is widely used for supervised learning tasks, including classiﬁca2on, regression, and ranking problems. XGBoost builds an ensemble of weak predic2on models, typically decision trees, to create a strong predic2ve model with high accuracy and generalizability.  How It Works  XGBoost sequen2ally builds a strong model by adding weak models that collec2vely minimize a predeﬁned loss func2on. It uses gradient boos2ng to op2mize the model by ﬁGng new models to the residuals of the previous models. XGBoost employs a combina2on of regulariza2on techniques and parallel processing to enhance model performance and reduce overﬁGng.  Mathema)cal Intui)on  XGBoost op2mizes the objec2ve func2on by compu2ng the ﬁrst and second deriva2ves of the loss func2on. It uses the Taylor series expansion to approximate the loss func2on, leading to a simpliﬁed yet eﬀec2ve op2miza2on process. XGBoost u2lizes techniques like gradient descent and tree pruning to eﬃciently handle complex datasets and achieve beKer generaliza2on. Limita)ons  Although XGBoost is known for its robustness and high performance, it can be computa2onally expensive and memory-intensive, par2cularly for large datasets. It may require ﬁne-tuning of various hyperparameters to achieve the best results, making it more complex to implement compared to simpler algorithms.'"
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "docs[0].page_content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "IDbd_9zMVXRZ",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "IDbd_9zMVXRZ",
        "outputId": "52975c00-ce4f-4d18-f813-32a059f2f57a"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'customiza2on and hyperparameter tuning, allowing users to op2mize model performance based on speciﬁc requirements. Disadvantages  Despite its advantages, XGBoost has certain limita2ons, such as the increased computa2onal complexity and longer training 2mes compared to simpler algorithms. It may require signiﬁcant computa2onal resources, limi2ng its applicability in resource-constrained environments. The black-box nature of the model can also hinder interpretability, making it challenging to understand the decision-making process for complex predic2ons.'"
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "docs[1].page_content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "lM16XiK7Ve81",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "id": "lM16XiK7Ve81",
        "outputId": "ee4b141a-dbc8-4f2a-f0d1-61807f7272b2"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'It may require ﬁne-tuning of various hyperparameters to achieve the best results, making it more complex to implement compared to simpler algorithms. Addi2onally, the interpretability of the resul2ng models may be challenging due to the complexity of the ensemble learning process. Advantages  XGBoost oﬀers several advantages, including its ability to handle complex, high-dimensional data and its robustness against overﬁGng. It provides high predic2ve accuracy and generalizability, making it suitable for a wide range of real-world applica2ons. XGBoost is highly scalable and can eﬃciently handle large datasets. It also oﬀers ﬂexibility in terms of'"
            ]
          },
          "execution_count": 52,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "docs[2].page_content"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ccc2d784",
      "metadata": {
        "id": "ccc2d784"
      },
      "source": [
        "## Addressing Specificity: working with metadata using self-query retriever\n",
        "\n",
        "But we have an interesting challenge: we often want to infer the metadata from the query itself.\n",
        "\n",
        "To address this, we can use `SelfQueryRetriever`, which uses an LLM to extract:\n",
        "\n",
        "1. The `query` string to use for vector search\n",
        "2. A metadata filter to pass in as well\n",
        "\n",
        "Most vector databases support metadata filters, so this doesn't require any new databases or indexes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "YfA7thLWWo7N",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YfA7thLWWo7N",
        "outputId": "d248c32f-7c43-4dde-f63a-126defbef5e7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting lark\n",
            "  Downloading lark-1.1.8-py3-none-any.whl (111 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/111.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m111.6/111.6 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: lark\n",
            "Successfully installed lark-1.1.8\n"
          ]
        }
      ],
      "source": [
        "!pip install lark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2_5NWzD9OH1b",
      "metadata": {
        "id": "2_5NWzD9OH1b"
      },
      "outputs": [],
      "source": [
        "from langchain.llms import OpenAI\n",
        "from langchain.retrievers.self_query.base import SelfQueryRetriever\n",
        "from langchain.chains.query_constructor.base import AttributeInfo\n",
        "#import lark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "p0Uk-zIXOJnO",
      "metadata": {
        "id": "p0Uk-zIXOJnO"
      },
      "outputs": [],
      "source": [
        "metadata_field_info = [\n",
        "    AttributeInfo(\n",
        "        name=\"source\",\n",
        "        description=\"The lecture the chunk is from, should be one of `machine_learning_XGBoost.pdf`, `machine_learning_DecisionTree.pdf`, or `machine_learning_LinearReg.pdf`\",\n",
        "        type=\"string\",\n",
        "    ),\n",
        "    AttributeInfo(\n",
        "        name=\"page\",\n",
        "        description=\"The page from the lecture\",\n",
        "        type=\"integer\",\n",
        "    ),\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "x5FPrf8BOLoH",
      "metadata": {
        "id": "x5FPrf8BOLoH"
      },
      "outputs": [],
      "source": [
        "document_content_description = \"Lecture notes\"\n",
        "llm = OpenAI(temperature=0)\n",
        "retriever = SelfQueryRetriever.from_llm(\n",
        "    llm,\n",
        "    vectordb,\n",
        "    document_content_description,\n",
        "    metadata_field_info,\n",
        "    verbose=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a4A4vkZTOOA2",
      "metadata": {
        "id": "a4A4vkZTOOA2"
      },
      "outputs": [],
      "source": [
        "question = \"What are the points to remember in Decision Tree ?\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "DFWOH3q2ahHj",
      "metadata": {
        "id": "DFWOH3q2ahHj"
      },
      "outputs": [],
      "source": [
        "docs = retriever.get_relevant_documents(question)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dw38snoQajoX",
      "metadata": {
        "id": "dw38snoQajoX"
      },
      "outputs": [],
      "source": [
        "for d in docs:\n",
        "    print(d.metadata)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "OE7JaZP7rmk0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OE7JaZP7rmk0",
        "outputId": "65097822-3d51-4d7f-ac13-2dc5d243b7bc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[]\n"
          ]
        }
      ],
      "source": [
        "print(docs)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "297b8168",
      "metadata": {
        "id": "297b8168"
      },
      "source": [
        "## Additional tricks: compression\n",
        "\n",
        "Another approach for improving the quality of retrieved docs is compression.\n",
        "\n",
        "Information most relevant to a query may be buried in a document with a lot of irrelevant text.\n",
        "\n",
        "Passing that full document through your application can lead to more expensive LLM calls and poorer responses.\n",
        "\n",
        "Contextual compression is meant to fix this."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "WQreErjwa7y8",
      "metadata": {
        "id": "WQreErjwa7y8"
      },
      "outputs": [],
      "source": [
        "from langchain.retrievers import ContextualCompressionRetriever\n",
        "from langchain.retrievers.document_compressors import LLMChainExtractor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b1om5n3fa-DB",
      "metadata": {
        "id": "b1om5n3fa-DB"
      },
      "outputs": [],
      "source": [
        "def pretty_print_docs(docs):\n",
        "    print(f\"\\n{'-' * 100}\\n\".join([f\"Document {i+1}:\\n\\n\" + d.page_content for i, d in enumerate(docs)]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "tEv-tk6Ca_02",
      "metadata": {
        "id": "tEv-tk6Ca_02"
      },
      "outputs": [],
      "source": [
        "# Wrap our vectorstore\n",
        "llm = OpenAI(temperature=0)\n",
        "compressor = LLMChainExtractor.from_llm(llm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bGOeIhMLbBCF",
      "metadata": {
        "id": "bGOeIhMLbBCF"
      },
      "outputs": [],
      "source": [
        "compression_retriever = ContextualCompressionRetriever(\n",
        "    base_compressor=compressor,\n",
        "    base_retriever=vectordb.as_retriever()\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Mzw2XBVCbChf",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mzw2XBVCbChf",
        "outputId": "0b100dd7-f0cb-441d-b9e0-fb3884bac362"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py:321: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py:321: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py:321: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py:321: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
            "  warnings.warn(\n",
            "WARNING:langchain.llms.base:Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for text-davinci-003 in organization org-A1eSRsZwugsl5YjO3kkNnH26 on requests per min. Limit: 3 / min. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing..\n",
            "WARNING:langchain.llms.base:Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for text-davinci-003 in organization org-A1eSRsZwugsl5YjO3kkNnH26 on requests per min. Limit: 3 / min. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing..\n",
            "WARNING:langchain.llms.base:Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for text-davinci-003 in organization org-A1eSRsZwugsl5YjO3kkNnH26 on requests per min. Limit: 3 / min. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing..\n",
            "WARNING:langchain.llms.base:Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised RateLimitError: Rate limit reached for text-davinci-003 in organization org-A1eSRsZwugsl5YjO3kkNnH26 on requests per min. Limit: 3 / min. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing..\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Document 1:\n",
            "\n",
            "\"its reliance on the linearity assumption between the dependent and independent variables\" and \"If the relationship between the variables is non-linear, the model may not accurately represent the data\" and \"linear regression is sensitive to outliers\" and \"its performance may be impacted by the presence of multicollinearity among the independent variables\"\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Document 2:\n",
            "\n",
            "\"its reliance on the linearity assumption between the dependent and independent variables\" and \"If the relationship between the variables is non-linear, the model may not accurately represent the data\" and \"linear regression is sensitive to outliers\" and \"its performance may be impacted by the presence of multicollinearity among the independent variables\"\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Document 3:\n",
            "\n",
            "Linear Regression is a fundamental supervised learning algorithm used in the ﬁeld of sta5s5cs and machine learning. It is employed to establish the rela5onship between a dependent variable and one or more independent variables. The objec5ve of linear regression is to ﬁnd the best-ﬁ?ng straight line that can depict the rela5onship between the variables. This line serves as a predic5ve model for future data points.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Document 4:\n",
            "\n",
            "Linear Regression is a fundamental supervised learning algorithm used in the ﬁeld of sta5s5cs and machine learning. It is employed to establish the rela5onship between a dependent variable and one or more independent variables. The objec5ve of linear regression is to ﬁnd the best-ﬁ?ng straight line that can depict the rela5onship between the variables. This line serves as a predic5ve model for future data points.\n"
          ]
        }
      ],
      "source": [
        "question = \"what did they say Linear Regression ?\"\n",
        "compressed_docs = compression_retriever.get_relevant_documents(question)\n",
        "pretty_print_docs(compressed_docs)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "82c4fc4d",
      "metadata": {
        "id": "82c4fc4d"
      },
      "source": [
        "## Combining various techniques"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "MMQPSN9qbuIp",
      "metadata": {
        "id": "MMQPSN9qbuIp"
      },
      "outputs": [],
      "source": [
        "compression_retriever = ContextualCompressionRetriever(\n",
        "    base_compressor=compressor,\n",
        "    base_retriever=vectordb.as_retriever(search_type = \"mmr\")\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "LSJz4yynbyo9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LSJz4yynbyo9",
        "outputId": "bf8e97eb-1228-4a49-9051-d2ea6e9314c9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Number of requested results 20 is greater than number of elements in index 12, updating n_results = 12\n",
            "/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py:321: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py:321: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py:321: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py:321: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
            "  warnings.warn(\n",
            "WARNING:langchain.llms.base:Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for text-davinci-003 in organization org-A1eSRsZwugsl5YjO3kkNnH26 on requests per min. Limit: 3 / min. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing..\n",
            "WARNING:langchain.llms.base:Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for text-davinci-003 in organization org-A1eSRsZwugsl5YjO3kkNnH26 on requests per min. Limit: 3 / min. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing..\n",
            "WARNING:langchain.llms.base:Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for text-davinci-003 in organization org-A1eSRsZwugsl5YjO3kkNnH26 on requests per min. Limit: 3 / min. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing..\n",
            "WARNING:langchain.llms.base:Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised RateLimitError: Rate limit reached for text-davinci-003 in organization org-A1eSRsZwugsl5YjO3kkNnH26 on requests per min. Limit: 3 / min. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing..\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Document 1:\n",
            "\n",
            "\"its reliance on the linearity assumption between the dependent and independent variables\" and \"If the relationship between the variables is non-linear, the model may not accurately represent the data\" and \"linear regression is sensitive to outliers\" and \"its performance may be impacted by the presence of multicollinearity among the independent variables\"\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Document 2:\n",
            "\n",
            "Linear Regression is a fundamental supervised learning algorithm used in the ﬁeld of sta5s5cs and machine learning. It is employed to establish the rela5onship between a dependent variable and one or more independent variables. The objec5ve of linear regression is to ﬁnd the best-ﬁ?ng straight line that can depict the rela5onship between the variables. This line serves as a predic5ve model for future data points.\n"
          ]
        }
      ],
      "source": [
        "question = \"what did they say Linear Regression ?\"\n",
        "compressed_docs = compression_retriever.get_relevant_documents(question)\n",
        "pretty_print_docs(compressed_docs)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6c2b63e1",
      "metadata": {
        "id": "6c2b63e1"
      },
      "source": [
        "## Other types of retrieval\n",
        "\n",
        "It's worth noting that vectordb as not the only kind of tool to retrieve documents.\n",
        "\n",
        "The `LangChain` retriever abstraction includes other ways to retrieve documents, such as TF-IDF or SVM."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Ej_th_Cvb-1J",
      "metadata": {
        "id": "Ej_th_Cvb-1J"
      },
      "outputs": [],
      "source": [
        "from langchain.retrievers import SVMRetriever\n",
        "from langchain.retrievers import TFIDFRetriever\n",
        "from langchain.document_loaders import PyPDFLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "jL7i9DzdcDaX",
      "metadata": {
        "id": "jL7i9DzdcDaX"
      },
      "outputs": [],
      "source": [
        "# Load PDF\n",
        "loader = PyPDFLoader(\"/content/machine_learning_XGBoost.pdf\")\n",
        "pages = loader.load()\n",
        "all_page_text=[p.page_content for p in pages]\n",
        "joined_page_text=\" \".join(all_page_text)\n",
        "\n",
        "# Split\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size = 1500,chunk_overlap = 150)\n",
        "splits = text_splitter.split_text(joined_page_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "u8QeAsOwcGaa",
      "metadata": {
        "id": "u8QeAsOwcGaa"
      },
      "outputs": [],
      "source": [
        "# question = \"What are major concepts for XGBoost topic ?\"\n",
        "# docs_svm = SVMRetriever.get_relevant_documents(question)\n",
        "# docs_svm[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "POkh3X4pcH2d",
      "metadata": {
        "id": "POkh3X4pcH2d"
      },
      "outputs": [],
      "source": [
        "# question = \"what did they say about matlab?\"\n",
        "# docs_tfidf=tfidf_retriever.get_relevant_documents(question)\n",
        "# docs_tfidf[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "id": "YdbR1r-JdNej",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "YdbR1r-JdNej",
        "outputId": "b6d5bb0a-8743-4cf2-fac0-012731927172"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'/Users/ashique/Playground/LLMDeepDive/docs/persistent_chroma_db.zip'"
            ]
          },
          "execution_count": 60,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import shutil\n",
        "\n",
        "# Folder path to be zipped\n",
        "folder_path = '/tmp/docs/chroma'  # Replace with your folder path\n",
        "\n",
        "# Destination path for the zip file\n",
        "output_zip_path = '/Users/ashique/Playground/LLMDeepDive/docs/persistent_chroma_db'  # Replace with your desired output path and filename\n",
        "\n",
        "# Use shutil library to create the zip file\n",
        "shutil.make_archive(output_zip_path, 'zip', folder_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f_GXkGfEd2uv",
      "metadata": {
        "id": "f_GXkGfEd2uv"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
