{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "1a4596ea-a631-416d-a2a4-3577c140493d",
      "metadata": {
        "id": "1a4596ea-a631-416d-a2a4-3577c140493d",
        "tags": []
      },
      "source": [
        "\n",
        "* `LangSmith` is a platform for building production-grade LLM applications.\n",
        "* It lets you debug, test, evaluate, and monitor chains and intelligent agents built on any LLM framework and seamlessly integrates with LangChain, the go-to open source framework for building with LLMs.\n",
        "\n",
        "* LangSmith provides several benefits for developing and evaluating conversational AI systems:\n",
        "\n",
        "  - Accelerates debugging of new conversation flows, agents, and toolsets.\n",
        "  -Enables visualization of relationships between components like chains, models, and retrievers.\n",
        "  - Supports testing different prompts and models for a specific module.\n",
        "  - Allows running chains repeatedly over datasets to assess consistency.\n",
        "  - Captures usage data to generate insights using analytics."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "A_sDSm9Guvk8",
      "metadata": {
        "id": "A_sDSm9Guvk8"
      },
      "source": [
        "# 10.1 Getting Started"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "rvZhHWzm6lDg",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rvZhHWzm6lDg",
        "outputId": "a8dab14b-e00c-4611-bccb-05af0764f802"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: langsmith in ./.venv/lib/python3.11/site-packages (0.1.33)\n",
            "Collecting langsmith\n",
            "  Downloading langsmith-0.1.52-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in ./.venv/lib/python3.11/site-packages (from langsmith) (3.9.15)\n",
            "Requirement already satisfied: pydantic<3,>=1 in ./.venv/lib/python3.11/site-packages (from langsmith) (2.6.4)\n",
            "Requirement already satisfied: requests<3,>=2 in ./.venv/lib/python3.11/site-packages (from langsmith) (2.31.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in ./.venv/lib/python3.11/site-packages (from pydantic<3,>=1->langsmith) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in ./.venv/lib/python3.11/site-packages (from pydantic<3,>=1->langsmith) (2.16.3)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in ./.venv/lib/python3.11/site-packages (from pydantic<3,>=1->langsmith) (4.10.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.11/site-packages (from requests<3,>=2->langsmith) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.11/site-packages (from requests<3,>=2->langsmith) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.11/site-packages (from requests<3,>=2->langsmith) (2.2.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.11/site-packages (from requests<3,>=2->langsmith) (2024.2.2)\n",
            "Downloading langsmith-0.1.52-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.4/116.4 kB\u001b[0m \u001b[31m122.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: langsmith\n",
            "  Attempting uninstall: langsmith\n",
            "    Found existing installation: langsmith 0.1.33\n",
            "    Uninstalling langsmith-0.1.33:\n",
            "      Successfully uninstalled langsmith-0.1.33\n",
            "Successfully installed langsmith-0.1.52\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!pip3 install -U langsmith"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "YF4y_1PHgWjS",
      "metadata": {
        "id": "YF4y_1PHgWjS"
      },
      "source": [
        "**How to Get the required KEYS**\n",
        "\n",
        "* LangSmith API Key : https://docs.smith.langchain.com/\n",
        "* LangChain API Key : https://smith.langchain.com/settings\n",
        "\n",
        "* Serper API Key : https://serper.dev/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "iOUiot2MN6MU",
      "metadata": {
        "id": "iOUiot2MN6MU"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from uuid import uuid4\n",
        "\n",
        "unique_id = uuid4().hex[0:8]\n",
        "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
        "os.environ[\"LANGCHAIN_PROJECT\"] = f\"Getting Started\"\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"Enter your API Key\"\n",
        "os.environ[\"SERPER_API_KEY\"] = \"Enter your API Key\"\n",
        "\n",
        "os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
        "os.environ[\"LANGCHAIN_API_KEY\"] = \"ls__446246ca5f6744558aedc927aa852c05\"  # Update with your API key\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "LHNK4cUW1qSF",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LHNK4cUW1qSF",
        "outputId": "ea59fa5d-6294-4a95-f86c-91bcf89221c0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "AIMessage(content='Hello! How can I assist you today?')"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langchain.chat_models import ChatOpenAI\n",
        "\n",
        "llm = ChatOpenAI()\n",
        "llm.invoke(\"Hello, world!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fgwNuRkVJ5-O",
      "metadata": {
        "id": "fgwNuRkVJ5-O"
      },
      "source": [
        "Check the LangSmith Platform for live tracking of your Actions. Click here https://smith.langchain.com/"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Gp3DYoFu2k-M",
      "metadata": {
        "id": "Gp3DYoFu2k-M"
      },
      "source": [
        "### 10.2 OpenAI Q&A"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "B-jdRWWf2kjH",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B-jdRWWf2kjH",
        "outputId": "252423d4-e6a2-43b0-af72-b0d674a20263"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dr. APJ Abdul Kalam, full name Avul Pakir Jainulabdeen Abdul Kalam, was an Indian scientist, politician, and the 11th President of India. He was born on October 15, 1931, in Rameswaram, Tamil Nadu, and died on July 27, 2015, in Shillong, Meghalaya. \n",
            "\n",
            "Dr. Kalam was known as the \"Missile Man of India\" for his significant contributions to India's space and missile programs. He played a crucial role in the development of India's first indigenous satellite launch vehicle (SLV-III), which successfully deployed the Rohini satellite in near-earth orbit in 1980. He also played a key role in the development of the Agni and Prithvi missiles.\n",
            "\n",
            "Apart from his scientific achievements, Dr. Kalam served as the President of India from 2002 to 2007. During his presidency, he focused on promoting education, especially in rural areas, and inspiring the youth of India to pursue scientific research and innovation.\n",
            "\n",
            "Dr. APJ Abdul Kalam was widely respected and admired for his humility, simplicity, and dedication to the country. His contributions to India's scientific and technological advancements, as well as his inspirational leadership, have made him one of the most beloved and influential figures in Indian history.\n"
          ]
        }
      ],
      "source": [
        "chat_model = ChatOpenAI() # temperature=0.0\n",
        "chat_model\n",
        "\n",
        "print(chat_model.predict(\"Hi !! Who is Dr.APJ Abdul Kalam ?\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "GqNcX0902Xc1",
      "metadata": {
        "id": "GqNcX0902Xc1"
      },
      "source": [
        "### 10.3 Integrate LangSmith with LangChain Chat Bot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "3i1SF5DI_zJt",
      "metadata": {
        "id": "3i1SF5DI_zJt"
      },
      "outputs": [],
      "source": [
        "import openai\n",
        "import os\n",
        "import sys\n",
        "sys.path.append('../..')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "FuPkDRzy_zGt",
      "metadata": {
        "id": "FuPkDRzy_zGt"
      },
      "outputs": [],
      "source": [
        "from langchain.document_loaders import PyPDFLoader\n",
        "\n",
        "# Load PDF\n",
        "loader = PyPDFLoader(\"/content/META-Q2-2023-Earnings-Call-Transcript.pdf\")\n",
        "docs = loader.load()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "svlaXWriDYHK",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "svlaXWriDYHK",
        "outputId": "724bca32-2ceb-40af-aa1d-eefe0ad55ded"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Document(page_content=\"1 \\n Meta Platforms , Inc. ( META ) \\nSecond Quarter 2023 Results Conference Call  \\nJuly 26th, 202 3 \\n \\nKen Dorell , Director , Investor Relations  \\n \\nThank you. Good afternoon and welcome to Meta Platforms second quarter 2023 earnings conference \\ncall. Joining me today to discuss our results are Mark Zuckerberg, CEO and Susan Li, CFO.  \\n \\nBefore we get started, I would like to take this opportunity to remind you that our remarks today will \\ninclude forward‐looking statements. Actual results may differ materially from t hose contemplated by \\nthese forward‐looking statements.  \\n \\nFactors that could cause these results to differ materially are set forth in today’s press release, and in \\nour quarterly report on form 10 -Q filed with the SEC. Any forward‐looking statements that we make on \\nthis call are based on assumptions as of today and we undertake no obligation to update these \\nstatements as a result of new information or future events.  \\n \\nDuring this call we will present both GAAP and certain non‐GAAP financial measures. A reconci liation of \\nGAAP to non‐GAAP measures is included in today’s earnings press release. The press release and an \\naccompanying investor presentation are available on our website at investor.fb.com.  \\n \\nAnd now, I’d like to turn the call over to Mark.  \\n \\nMark Zuckerb erg, CEO  \\n \\nThanks Ken, and thanks everyone for joining.  \\n  \\nThis was a good quarter for our business. We're seeing strong engagement trends across our apps. \\nThere are now more than 3.8 billion people who use at least one of our apps every month. Facebook \\nnow has more than 3 billion monthly actives -- with daily actives continuing to grow around the world, \\nincluding in the US and Canada.  \\n \\nIn addition to our core products performing well, I think we have the most exciting roadmap ahead that \\nI've se en in a while. We've got continued progress on Threads, Reels, Llama 2, and some ground -\\nbreaking AI products in the pipeline as well as the Quest 3 launch com ing up this fall. We're heads down \\nexecuting on all of this right now, and it's really good to see the decisions and investments that we've \\nmade start to play out.  \\n \\nOn Threads, briefly, I'm quite optimistic about our trajectory. We saw unprecedented growth out of the \\ngate and more importantly we're seeing more people coming back daily than I'd expected. And now, \\nwe're focuse d on retention and improving the basics. And then a fter that, we'll focus on growing the \\ncommunity to the scale we think is possible. Only after that will we work on monetization. We've run \\nthis playbook many times before -- with Facebook, Instagram, WhatsApp, Stories, Reels, and more -- and \\nthis is as good of a start as we could have hoped for, so I'm really happy with the path we're on here.    \\n \\nOne note  that I want to mention about the Threads launch related to our Year of Efficiency is that the \\nproduct was built by a relatively small team on a tight timeline. We've already seen a number of \", metadata={'source': '/content/META-Q2-2023-Earnings-Call-Transcript.pdf', 'page': 0})"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "docs[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "1yTPVbQJCy5G",
      "metadata": {
        "id": "1yTPVbQJCy5G"
      },
      "outputs": [],
      "source": [
        "# Split\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size = 1500,\n",
        "    chunk_overlap = 150\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "jdNk-vzYC2Ok",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jdNk-vzYC2Ok",
        "outputId": "db83f9b1-ccd8-4d17-ad8b-be4297285d8e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "55"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "splits = text_splitter.split_documents(docs)\n",
        "len(splits)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "dgOUQWkJET7P",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dgOUQWkJET7P",
        "outputId": "2c14c2e0-cd5d-4804-d842-a7f084421d44"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "55\n"
          ]
        }
      ],
      "source": [
        "from langchain.vectorstores import Chroma\n",
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "\n",
        "persist_directory = 'docs/chroma/'\n",
        "embedding = OpenAIEmbeddings()\n",
        "vectordb = Chroma.from_documents(\n",
        "    documents=splits,\n",
        "    embedding=embedding,\n",
        "    persist_directory=persist_directory\n",
        ")\n",
        "\n",
        "print(vectordb._collection.count())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "z4odHa-THXz0",
      "metadata": {
        "id": "z4odHa-THXz0"
      },
      "outputs": [],
      "source": [
        "from langchain.chat_models import ChatOpenAI\n",
        "\n",
        "llm_name = 'gpt-3.5-turbo'\n",
        "llm = ChatOpenAI(model_name=llm_name, temperature=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "jGArqjD_JQ1S",
      "metadata": {
        "id": "jGArqjD_JQ1S"
      },
      "outputs": [],
      "source": [
        "# Build prompt\n",
        "\n",
        "from langchain.prompts import PromptTemplate\n",
        "template = \"\"\" Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer. Use three sentences maximum. Keep the answer as concise as possible. Always say \"thanks for asking!\" at the end of the answer.\n",
        "{context}\n",
        "Question: {question}\n",
        "Helpful Answer: \"\"\"\n",
        "\n",
        "QA_CHAIN_PROMPT = PromptTemplate(input_variables=[\"context\", \"question\"],template=template,)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "tsYm9kgXPIcr",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "tsYm9kgXPIcr",
        "outputId": "6e2590bd-66d9-4876-ce6c-828bcbfe7f99"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:langchain.llms.base:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised Timeout: Request timed out: HTTPSConnectionPool(host='api.openai.com', port=443): Read timed out. (read timeout=600).\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'The total revenue for Q2 was $32.0 billion. Thanks for asking!'"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Run chain\n",
        "from langchain.chains import RetrievalQA\n",
        "question = \"what is the total revenue ? \"\n",
        "qa_chain = RetrievalQA.from_chain_type(llm,\n",
        "                                       retriever=vectordb.as_retriever(),\n",
        "                                       return_source_documents=True,\n",
        "                                       chain_type_kwargs={\"prompt\": QA_CHAIN_PROMPT})\n",
        "\n",
        "\n",
        "result = qa_chain({\"query\": question})\n",
        "result[\"result\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "G5lPVN5g0LZo",
      "metadata": {
        "id": "G5lPVN5g0LZo"
      },
      "source": [
        "### 10.4 Agents - Search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "OsDzGbY3VdaG",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OsDzGbY3VdaG",
        "outputId": "75458d64-e63d-4976-ef6b-95933ae7e3d2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting google-search-results\n",
            "  Downloading google_search_results-2.4.2.tar.gz (18 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from google-search-results) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->google-search-results) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->google-search-results) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->google-search-results) (1.26.18)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->google-search-results) (2023.7.22)\n",
            "Building wheels for collected packages: google-search-results\n",
            "  Building wheel for google-search-results (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for google-search-results: filename=google_search_results-2.4.2-py3-none-any.whl size=32004 sha256=12653af3d7cfb6c4b41afbe1f75496163631d4388fe809a6fac254f94988690b\n",
            "  Stored in directory: /root/.cache/pip/wheels/d3/b2/c3/03302d12bb44a2cdff3c9371f31b72c0c4e84b8d2285eeac53\n",
            "Successfully built google-search-results\n",
            "Installing collected packages: google-search-results\n",
            "Successfully installed google-search-results-2.4.2\n"
          ]
        }
      ],
      "source": [
        "!pip install google-search-results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "LWv3DcUQXCnV",
      "metadata": {
        "id": "LWv3DcUQXCnV"
      },
      "outputs": [],
      "source": [
        "from langchain.tools import DuckDuckGoSearchRun\n",
        "from langchain.agents import Tool\n",
        "from langchain.agents import load_tools\n",
        "from langchain.agents import initialize_agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "dEFYS1GXVrY6",
      "metadata": {
        "id": "dEFYS1GXVrY6"
      },
      "outputs": [],
      "source": [
        "QUERY = \"Who is the Hitman of Indian Cricket Team ? What is his age multiplied by 2 ?\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "id": "TlWCfQ8v0Om6",
      "metadata": {
        "id": "TlWCfQ8v0Om6"
      },
      "outputs": [],
      "source": [
        "from langchain.llms import OpenAI\n",
        "\n",
        "llm = OpenAI(model_name=\"text-davinci-003\" ,temperature=0)\n",
        "tools = load_tools([\"google-serper\", \"llm-math\"], llm=llm)\n",
        "agent = initialize_agent(tools, llm, agent=\"zero-shot-react-description\", verbose=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "id": "U-2w1i-bYVzY",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 322
        },
        "id": "U-2w1i-bYVzY",
        "outputId": "49729461-b92f-4ace-b774-772ef44c39ee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m I need to find out who the Hitman is and then calculate his age multiplied by 2.\n",
            "Action: google_serper\n",
            "Action Input: \"Hitman of Indian Cricket Team\"\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3mThis achievement further solidifies his status as one of India's premier batsmen and a cricketing legend. On the 22nd of October 2023, during a thrilling encounter against New Zealand, Rohit Sharma, fondly known as the 'Hitman,' etched his name in the annals of cricket history.\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m I need to find out Rohit Sharma's age.\n",
            "Action: google_serper\n",
            "Action Input: \"Rohit Sharma age\"\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3m36 years\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer\n",
            "Final Answer: 72\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'72'"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "agent.run(QUERY)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "quDn0reZYgN8",
      "metadata": {
        "id": "quDn0reZYgN8"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
