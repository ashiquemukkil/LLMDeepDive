{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation Metrics\n",
    "## ROUGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset,load_metric\n",
    "from transformers import pipeline\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### load any dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "huggingface_dataset_name = \"knkarthick/dialogsum\"\n",
    "dataset = load_dataset(huggingface_dataset_name, split=\"test[:10%]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "model_name='google/flan-t5-base'\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=True)\n",
    "\n",
    "summarizer = pipeline(\"summarization\",model=model,tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'test_0_1',\n",
       " 'dialogue': \"#Person1#: Ms. Dawson, I need you to take a dictation for me.\\n#Person2#: Yes, sir...\\n#Person1#: This should go out as an intra-office memorandum to all employees by this afternoon. Are you ready?\\n#Person2#: Yes, sir. Go ahead.\\n#Person1#: Attention all staff... Effective immediately, all office communications are restricted to email correspondence and official memos. The use of Instant Message programs by employees during working hours is strictly prohibited.\\n#Person2#: Sir, does this apply to intra-office communications only? Or will it also restrict external communications?\\n#Person1#: It should apply to all communications, not only in this office between employees, but also any outside communications.\\n#Person2#: But sir, many employees use Instant Messaging to communicate with their clients.\\n#Person1#: They will just have to change their communication methods. I don't want any - one using Instant Messaging in this office. It wastes too much time! Now, please continue with the memo. Where were we?\\n#Person2#: This applies to internal and external communications.\\n#Person1#: Yes. Any employee who persists in using Instant Messaging will first receive a warning and be placed on probation. At second offense, the employee will face termination. Any questions regarding this new policy may be directed to department heads.\\n#Person2#: Is that all?\\n#Person1#: Yes. Please get this memo typed up and distributed to all employees before 4 pm.\",\n",
       " 'summary': 'Ms. Dawson helps #Person1# to write a memo to inform every employee that they have to change the communication method and should not use Instant Messaging anymore.',\n",
       " 'topic': 'communication method'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ashique/Playground/LLMDeepDive/.venv/lib/python3.11/site-packages/datasets/load.py:756: FutureWarning: The repository for rouge contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.18.0/metrics/rouge/rouge.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reference_summary :Ms. Dawson helps #Person1# to write a memo to inform every employee that they have to change the communication method and should not use Instant Messaging anymore.\n",
      "generated_summary :#Person1#: Ms. Dawson, I need you to take a dictation for me. Is it OK to use instant messaging in this office?\n",
      "\n",
      "\n",
      "ROUGE-1: 0.36734693877551017\n",
      "ROUGE-2: 0.12765957446808512\n",
      "ROUGE-L: 0.32653061224489793\n",
      "ROUGE-LSUM: 0.2738457084961644\n",
      "---------------------\n",
      "reference_summary :In order to prevent employees from wasting time on Instant Message programs, #Person1# decides to terminate the use of those programs and asks Ms. Dawson to send out a memo to all employees by the afternoon.\n",
      "generated_summary :#Person1#: Ms. Dawson, I need you to take a dictation for me. Is it OK to use instant messaging in this office?\n",
      "\n",
      "\n",
      "ROUGE-1: 0.31034482758620685\n",
      "ROUGE-2: 0.03571428571428571\n",
      "ROUGE-L: 0.20689655172413793\n",
      "ROUGE-LSUM: 0.18431855500821015\n",
      "---------------------\n",
      "reference_summary :Ms. Dawson takes a dictation for #Person1# about prohibiting the use of Instant Message programs in the office. They argue about its reasonability but #Person1# still insists.\n",
      "generated_summary :#Person1#: Ms. Dawson, I need you to take a dictation for me. Is it OK to use instant messaging in this office?\n",
      "\n",
      "\n",
      "ROUGE-1: 0.40816326530612246\n",
      "ROUGE-2: 0.12765957446808512\n",
      "ROUGE-L: 0.36734693877551017\n",
      "ROUGE-LSUM: 0.3010565928499059\n",
      "---------------------\n"
     ]
    }
   ],
   "source": [
    "rouge = load_metric(\"rouge\")\n",
    "\n",
    "# Calculate ROUGE scores for each example in the dataset\n",
    "for example in dataset.select(range(3)) :\n",
    "    reference_summary = example[\"summary\"]\n",
    "    generated_summary = summarizer(example[\"dialogue\"])[0][\"summary_text\"]\n",
    "    \n",
    "    # Calculate ROUGE scores\n",
    "    rouge_scores = rouge.compute(predictions=[generated_summary], references=[[reference_summary]])\n",
    "    print(f\"reference_summary :{reference_summary}\")\n",
    "    print(f\"generated_summary :{generated_summary}\")\n",
    "    print(f\"\\n\")\n",
    "    print(f\"ROUGE-1: {rouge_scores['rouge1'].mid.fmeasure}\")\n",
    "    print(f\"ROUGE-2: {rouge_scores['rouge2'].mid.fmeasure}\")\n",
    "    print(f\"ROUGE-L: {rouge_scores['rougeL'].mid.fmeasure}\")\n",
    "\n",
    "    # Calculate and print ROUGE LSUM\n",
    "    rouge_lsum = (rouge_scores['rouge1'].mid.fmeasure + rouge_scores['rouge2'].mid.fmeasure + rouge_scores['rougeL'].mid.fmeasure) / 3\n",
    "    print(f\"ROUGE-LSUM: {rouge_lsum}\")\n",
    "    print(\"---------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BLEU "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ashique/Playground/LLMDeepDive/.venv/lib/python3.11/site-packages/datasets/load.py:756: FutureWarning: The repository for sacrebleu contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.18.0/metrics/sacrebleu/sacrebleu.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reference_summary :Ms. Dawson helps #Person1# to write a memo to inform every employee that they have to change the communication method and should not use Instant Messaging anymore.\n",
      "generated_summary :#Person1#: Ms. Dawson, I need you to take a dictation for me. Is it OK to use instant messaging in this office?\n",
      "BLEU: 8.748599594163373\n",
      "BLEU (with brevity penalty): 6.970039653378489\n",
      "reference_summary :In order to prevent employees from wasting time on Instant Message programs, #Person1# decides to terminate the use of those programs and asks Ms. Dawson to send out a memo to all employees by the afternoon.\n",
      "generated_summary :#Person1#: Ms. Dawson, I need you to take a dictation for me. Is it OK to use instant messaging in this office?\n",
      "BLEU: 6.33328398876227\n",
      "BLEU (with brevity penalty): 3.3516583823616477\n",
      "reference_summary :Ms. Dawson takes a dictation for #Person1# about prohibiting the use of Instant Message programs in the office. They argue about its reasonability but #Person1# still insists.\n",
      "generated_summary :#Person1#: Ms. Dawson, I need you to take a dictation for me. Is it OK to use instant messaging in this office?\n",
      "BLEU: 10.073834719391199\n",
      "BLEU (with brevity penalty): 8.025859076072193\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "bleu = load_metric(\"sacrebleu\")\n",
    "\n",
    "# Calculate BLEU scores for each example in the dataset\n",
    "for example in dataset.select(range(3)):\n",
    "    reference_summary = example[\"summary\"]\n",
    "    generated_summary = summarizer(example[\"dialogue\"])[0][\"summary_text\"]\n",
    "    \n",
    "    # Calculate BLEU scores\n",
    "    bleu_output = bleu.compute(predictions=[generated_summary], references=[[reference_summary]])\n",
    "    \n",
    "    print(f\"reference_summary :{reference_summary}\")\n",
    "    print(f\"generated_summary :{generated_summary}\")\n",
    "    # Print BLEU scores\n",
    "    print(f\"BLEU: {bleu_output['score']}\")\n",
    "\n",
    "    # Calculate brevity penalty\n",
    "    reference_length = len(reference_summary.split())\n",
    "    generated_length = len(generated_summary.split())\n",
    "    brevity_penalty = min(1, np.exp(1 - reference_length / generated_length))\n",
    "    \n",
    "    # Calculate BLEU score with brevity penalty\n",
    "    bleu_score_with_bp = bleu_output['score'] * brevity_penalty\n",
    "    \n",
    "    # Print BLEU score with brevity penalty\n",
    "    print(f\"BLEU (with brevity penalty): {bleu_score_with_bp}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
